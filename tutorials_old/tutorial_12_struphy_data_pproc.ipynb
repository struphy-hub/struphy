{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Data, post processing and standard plots\n",
    "\n",
    "Topics coverd in this tutorial:\n",
    "\n",
    "- Look at the data generated from a Struphy simulation of the model [LinearMHDVlasovCC](https://struphy.pages.mpcdf.de/struphy/sections/models.html#struphy.models.hybrid.LinearMHDVlasovCC).\n",
    "- Run the post processing file `strupy/post_processing/pproc_struphy/main.py`, which is executed upon calling\n",
    "    ```\n",
    "    $ struphy pproc DIR\n",
    "    ```\n",
    "    from the console (we will not invoke the console and run directly from the notebook).\n",
    "- Inspect the data generated during post processing.\n",
    "- Extract the time grid.\n",
    "- Look at binning data of the kinetic distribution function (in v and in x-v space).\n",
    "- Look at 1D snapshots of one component of the magnetic field.\n",
    "\n",
    "Let us generate the data for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{'struphy run LinearMHDVlasovCC -i tutorials/params_02.yml -o tutorial_02/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Data generated by Struphy runs\n",
    "\n",
    "At first, we look at the raw data coming from the simulation (before post processing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import struphy\n",
    "\n",
    "path_out = os.path.join(struphy.__path__[0], \"io/out\", \"tutorial_02\")\n",
    "\n",
    "print(path_out)\n",
    "os.listdir(path_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two files and one folder named `data/` have been created by the simulation. The file `parameters.yml` is a copy of the parameter file used in the simulation. Let us check the metadata in `meta.txt`, where we can find some useful information about the simulation, such as date of execution, operating system, number of processes etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_out, \"meta.txt\")) as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now inspect the content of the `data/` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(path_out, \"data/\")\n",
    "\n",
    "os.listdir(path_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the simulation was ran with only one MPI process from a notebook, only one `.hdf5` file has been created (on process 0). In general, one such file will be created for each process. Let us inpect the content of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(os.path.join(path_data, \"data_proc0.hdf5\"), \"r\") as f:\n",
    "    for key in f.keys():\n",
    "        print(key + \"/\")\n",
    "        for subkey in f[key].keys():\n",
    "            print(\"    \" + subkey + \"/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see five top level keys under which data is stored:\n",
    "\n",
    "1. `feec` stores the finite element coefficients of the electromagnetic fields (only the magentic field 'b2' in this example) and of each fluid species (only one species `mhd` in this case).\n",
    "2. `kinetic` stores, for each kinetic species (only one species `energetic_ions` in this case), the binning data of the distribution function and a certain number of selected marker trajectories (can be specified in the parameters file).\n",
    "3. `restart` stores data in case the simualtion has been interrupted.\n",
    "4. `scalar` stores the scalar quantities of the simulation, such as energies for instance.\n",
    "5. `time` stores the time grid.\n",
    "\n",
    "## Data post processing\n",
    "\n",
    "As a user, we do not need to access the above data directly. This is handled by Struphy's main post processing routine, which should usually be called from the console:\n",
    "\n",
    "        $ struphy pproc DIR\n",
    "        \n",
    "Here, we look at this routine in a bit more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struphy.post_processing.pproc_struphy import main\n",
    "\n",
    "help(main)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see one manadatory argument, namely the `path` to the simulation output folder. Let us perform the post processing on our example folder. This will perform the following steps:\n",
    "\n",
    "1. Creation of Psydac FemFields.\n",
    "2. Evaluation of fields on the grid specified by `celldivide`.\n",
    "3. Creation of `.vtk` files for further diagnostics in Paraview.\n",
    "4. Evaluation of marker orbits on the mapped domain (Euclidean space).\n",
    "5. Collection of binning data of the distriution function (and evaluation of background in case of df-methods) from all processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(path_out, physical=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we inspect again the simulation folder after post processing, we see that an additional folder `post_processing/` has been created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(path_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(path_out, \"post_processing\")\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us extract the time grid of the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "t_grid = np.load(os.path.join(data_path, \"t_grid.npy\"))\n",
    "t_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinetic data\n",
    "\n",
    "First, we look at `kinetic_data/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinetic_path = os.path.join(data_path, \"kinetic_data\")\n",
    "\n",
    "print(os.listdir(kinetic_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kinetic_data/` contains one folder for each kinetic species (here just one species `energetic_ions/`). Let us inspect its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_path = os.path.join(kinetic_path, \"energetic_ions\")\n",
    "\n",
    "os.listdir(ep_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two kinds of kinetic data:  \n",
    "\n",
    "1. the binned `distribution_function/` ,\n",
    "2. particle `orbits/` of selected markers, which can be chosen in the parameter file.\n",
    "\n",
    "### Particle binning plots\n",
    "\n",
    "Details on the mathematics of particle binning can be found under https://struphy.pages.mpcdf.de/struphy/sections/discretization.html#particle-binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = os.path.join(ep_path, \"distribution_function\")\n",
    "\n",
    "print(os.listdir(f_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under `distribution_function/` we find the two folders `e1_v1/` and `v1/`, respectively, one for each binning of $f$ during the simulation. The binning directions have been defined in the parameter file before the run. \n",
    "\n",
    "You can do several binnings during one simulation. For an *n*-dimensional binning in phase space, there are *n+1* `.npy` files created in the respective folder: one file `f_binned.npy` with the binned distribution function, and *n* files with with the corresponding 1d phase space grids in each direction. The naming convention is as follows:\n",
    "\n",
    "1. Suppose we want 1-dimensional binning in the direction `v1` in velocity space. The folder is then called `v1`, the binned distribution function is saved under `v1/f_binned.npy` and the velocity binning grid is saved under `v1/grid_v1.npy`. The same could be done for instance in position space along the coordinate `e2`, which would lead to files `e2/f_binned.npy` and `e2/grid_e2.npy`, respectively.\n",
    "\n",
    "2. Suppose we want to do 2-dimensional binning in the $(e_1,v_1)$ subspace of the phase space. In this case the folder is called `e1_v1`, the distribution function is saved under `e1_v1/f_binned.npy`, the $e_1$-grid is under `e1_v1/grid_e1.npy` and the $v_1$-grid is under `e1_v1/grid_v1.npy`. \n",
    "\n",
    "3. The kind of binnings are defined in the parameter file under `kinetic/<species_name>/save_data/f/slices`. There you can define a list where each string entry defines one binning. For example, `['v1', 'e1_v1', 'e1_e2', 'v1_v2_v3']` would define four binnings in different subspaces of the phase space.\n",
    "\n",
    "Let us now plot the binned distribution function. In this example, two binnings have been performed during the simulation, namely `v1/` and `e1_v1/`. We shall perform the 1d plots first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_v1 = np.load(os.path.join(f_path, \"v1/\", \"grid_v1.npy\"))\n",
    "f_binned = np.load(os.path.join(f_path, \"v1/\", \"f_binned.npy\"))\n",
    "\n",
    "print(grid_v1.shape)\n",
    "print(f_binned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the first index in the binning data `f_binned.npy` denotes the time index, whereas the second index is the grid index. Let us plot the data at four different instances in time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "steps = [0, 1, 2, -1]\n",
    "for n, step in enumerate(steps):\n",
    "    plt.subplot(2, 2, n + 1)\n",
    "    plt.plot(grid_v1, f_binned[step], label=f\"time = {t_grid[step]}\")\n",
    "    plt.xlabel(\"v1\")\n",
    "    plt.ylabel(\"fvol(v1)\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2d plots are working in an analogous fashion. Here, we use pyplot's `pcolor` to display 2d data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_e1 = np.load(os.path.join(f_path, \"e1_v1/\", \"grid_e1.npy\"))\n",
    "grid_v1 = np.load(os.path.join(f_path, \"e1_v1/\", \"grid_v1.npy\"))\n",
    "f_binned = np.load(os.path.join(f_path, \"e1_v1/\", \"f_binned.npy\"))\n",
    "\n",
    "print(grid_e1.shape)\n",
    "print(grid_v1.shape)\n",
    "print(f_binned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the first index in `f_binned.npy` is the time index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "steps = [0, 1, 2, -1]\n",
    "for n, step in enumerate(steps):\n",
    "    plt.subplot(2, 2, n + 1)\n",
    "    plt.pcolor(grid_e1, grid_v1, f_binned[step].T, label=f\"time = {t_grid[step]}\")\n",
    "    plt.xlabel(\"e1\")\n",
    "    plt.ylabel(\"v1\")\n",
    "    plt.title(\"fvol(e1, v1)\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle orbits\n",
    "\n",
    "Let's see how the marker `orbits/` are stored in Struphy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbits_path = os.path.join(ep_path, \"orbits\")\n",
    "\n",
    "print(len(os.listdir(orbits_path)))\n",
    "for el in sorted(os.listdir(orbits_path)):\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each time step *n* (including *n=0*) there is one `.txt` and one `.npy` file of the name `<species_name>_n`. These files holds the positions **in physical space** of the designated markers, of which we print the first six:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = np.load(os.path.join(orbits_path, \"energetic_ions_00.npy\"))\n",
    "\n",
    "with open(os.path.join(orbits_path, \"energetic_ions_00.txt\")) as file:\n",
    "    orbit_str = file.read()\n",
    "\n",
    "markers_txt = orbit_str.split(\"\\n\")\n",
    "markers_txt[:6]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column holds the marker ID number. Actually, the `.npy` files hold also the marker velocities, not just the positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the markers at the initial time $t=0$ in the $(x, y)$-plane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(markers[:, 1], markers[:, 2])\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEEC data\n",
    "\n",
    "Last but not least we look at some `fields_data/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluid_path = os.path.join(data_path, \"fields_data\")\n",
    "\n",
    "print(os.listdir(fluid_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fields_data/` contains binary files for physical and logical grids as well as the following folders:\n",
    "\n",
    "1. `em_fields/` for the electromagnetic fields evaluated at the grids.\n",
    "2. One fluid species `mhd/` for the mhd variables evaluated at the grids. Note that the magnetic field is stored under `em_fields/`.\n",
    "3. `vtk/` for viewing FEEC variables in Paraview.\n",
    "\n",
    "Let us inspect the content of `em_fields/` and `mhd/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(fluid_path, \"em_fields\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(fluid_path, \"mhd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this is where the FEEC variables evaluated at the grid points are stored. Since this data is stored in binary format, we use `pickle` for loading: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(fluid_path, \"grids_phy.bin\"), \"rb\") as file:\n",
    "    x_grid, y_grid, z_grid = pickle.load(file)\n",
    "\n",
    "print(type(x_grid))\n",
    "print(x_grid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `grids_phy.bin` leads to a list of length three, each entry corresponding to a meshgrid of the respective direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fluid_path, \"em_fields\", \"b_field_phy.bin\"), \"rb\") as file:\n",
    "    b2 = pickle.load(file)\n",
    "\n",
    "print(type(b2))\n",
    "print(len(b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By contrast, `b2_phy.bin` leads to a dictionary with *n+1* keys, where *n* is the number of time steps saved during the simulation. \n",
    "\n",
    "The keys are the actual time (not the index!) of the time step and the values are lists holding the three components of the magnetic field in physical space (pushed forward 2-form):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in b2.items():\n",
    "    print(key)\n",
    "    print(type(val))\n",
    "    for va in val:\n",
    "        print(va.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall plot the *z*-component of the *B*-field as a function of *x*, at eight dfferent instances in time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "steps = [0, 1, 2, 3, 4, 5, 6, -1]\n",
    "for n, step in enumerate(steps):\n",
    "    t = t_grid[step]\n",
    "    plt.subplot(4, 2, n + 1)\n",
    "    plt.plot(x_grid[:, 0, 0], b2[t][2][:, 0, 0], label=f\"time = {t}\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"$B_z$(x)\")\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
